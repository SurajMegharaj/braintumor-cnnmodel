{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMv6MD4uehK2rbOpEkGqft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SurajMegharaj/braintumor-cnnmodel/blob/main/Cnn_tumor_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_73238fnmqrd"
      },
      "outputs": [],
      "source": [
        "!pip install split-folders\n",
        "!pip install torch-summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set(style='darkgrid')\n",
        "import copy\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image .\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import ImageFolder\n",
        "import splitfolders\n",
        "from torchsummary import summary\n",
        "import torch.nn.functional as F\n",
        "import pathlib\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "from tqdm.notebook import trange, tqdm\n",
        "from torch import optim\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "9oUxc0ykmuZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df = pd.read_csv('/kaggle/input/brian-tumor-dataset/metadata.csv')\n",
        "print(labels_df.head().to_markdown())"
      ],
      "metadata": {
        "id": "mGfAclVrmyJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set')"
      ],
      "metadata": {
        "id": "CPjDPon9nKVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.shape\n"
      ],
      "metadata": {
        "id": "ueX1lurUnOVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Path\n",
        "data_dir = '/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set'\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "\n",
        "# Splitting dataset to train_set, val_set and test_set\n",
        "splitfolders.ratio(data_dir, output='brain', seed=20, ratio=(0.8, 0.2))\n",
        "\n",
        "\n",
        "# New dataset path\n",
        "data_dir = '/kaggle/working/brain'\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "metadata": {
        "id": "k71LLBKOnRGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define transformation\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = [0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225])\n",
        "   ]\n",
        ")"
      ],
      "metadata": {
        "id": "GiXPOiJdnUD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.ImageFolder(data_dir.joinpath(\"train\"), transform=transform)\n",
        "train_set.transform\n",
        "val_set = torchvision.datasets.ImageFolder(data_dir.joinpath(\"val\"), transform=transform)\n",
        "val_set.transform"
      ],
      "metadata": {
        "id": "zMpBexrHnXbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualiztion some images from Train Set\n",
        "CLA_label = {\n",
        "    0 : 'Brain Tumor',\n",
        "    1 : 'Healthy'\n",
        "}\n",
        "figure = plt.figure(figsize=(10, 10))\n",
        "cols, rows = 4, 4\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
        "    img, label = train_set[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(CLA_label[label])\n",
        "    plt.axis(\"off\")\n",
        "    img_np = img.numpy().transpose((1, 2, 0))\n",
        "    # Clip pixel values to [0, 1]\n",
        "    img_valid_range = np.clip(img_np, 0, 1)\n",
        "    plt.imshow(img_valid_range)\n",
        "    plt.suptitle('Brain Images', y=0.95)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JbzCs0XCnaG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size = batch_size, shuffle = True, num_workers = 2)"
      ],
      "metadata": {
        "id": "N3fQ4lCtndMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in {'Training data': train_loader, \"Validation data\": val_loader}.items():\n",
        "    for X, y in value:\n",
        "        print(f\"{key}:\")\n",
        "        print(f\"Shape of X : {X.shape}\")\n",
        "        print(f\"Shape of y: {y.shape} {y.dtype}\\n\")\n",
        "        break"
      ],
      "metadata": {
        "id": "QZkHIq1snf93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''This function can be useful in determining the output size of a convolutional layer in a neural network,\n",
        "given the input dimensions and the convolutional layer's parameters.'''\n",
        "\n",
        "def findConv2dOutShape(hin,win,conv,pool=2):\n",
        "    # get conv arguments\n",
        "    kernel_size = conv.kernel_size\n",
        "    stride=conv.stride\n",
        "    padding=conv.padding\n",
        "    dilation=conv.dilation\n",
        "\n",
        "    hout=np.floor((hin+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
        "    wout=np.floor((win+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
        "\n",
        "    if pool:\n",
        "        hout/=pool\n",
        "        wout/=pool\n",
        "    return int(hout),int(wout)"
      ],
      "metadata": {
        "id": "dxLrZ2JlnjZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Architecture For CNN_TUMOR Model\n",
        "class CNN_TUMOR(nn.Module):\n",
        "\n",
        "    # Network Initialisation\n",
        "    def __init__(self, params):\n",
        "\n",
        "        super(CNN_TUMOR, self).__init__()\n",
        "\n",
        "        Cin,Hin,Win = params[\"shape_in\"]\n",
        "        init_f = params[\"initial_filters\"]\n",
        "        num_fc1 = params[\"num_fc1\"]\n",
        "        num_classes = params[\"num_classes\"]\n",
        "        self.dropout_rate = params[\"dropout_rate\"]\n",
        "\n",
        "        # Convolution Layers\n",
        "        self.conv1 = nn.Conv2d(Cin, init_f, kernel_size=3)\n",
        "        h,w=findConv2dOutShape(Hin,Win,self.conv1)\n",
        "        self.conv2 = nn.Conv2d(init_f, 2*init_f, kernel_size=3)\n",
        "        h,w=findConv2dOutShape(h,w,self.conv2)\n",
        "        self.conv3 = nn.Conv2d(2*init_f, 4*init_f, kernel_size=3)\n",
        "        h,w=findConv2dOutShape(h,w,self.conv3)\n",
        "        self.conv4 = nn.Conv2d(4*init_f, 8*init_f, kernel_size=3)\n",
        "        h,w=findConv2dOutShape(h,w,self.conv4)\n",
        "\n",
        "        # compute the flatten size\n",
        "        self.num_flatten=h*w*8*init_f\n",
        "        self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n",
        "        self.fc2 = nn.Linear(num_fc1, num_classes)\n",
        "\n",
        "    def forward(self,X):\n",
        "\n",
        "        # Convolution & Pool Layers\n",
        "        X = F.relu(self.conv1(X));\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = F.relu(self.conv2(X))\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = F.relu(self.conv3(X))\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = F.relu(self.conv4(X))\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = X.view(-1, self.num_flatten)\n",
        "        X = F.relu(self.fc1(X))\n",
        "        X = F.dropout(X, self.dropout_rate)\n",
        "        X = self.fc2(X)\n",
        "        return F.log_softmax(X, dim=1)"
      ],
      "metadata": {
        "id": "zlGDE3_8nnAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_model={\n",
        "        \"shape_in\": (3,256,256),\n",
        "        \"initial_filters\": 8,\n",
        "        \"num_fc1\": 100,\n",
        "        \"dropout_rate\": 0.25,\n",
        "        \"num_classes\": 2}\n",
        "\n",
        "# Create instantiation of Network class\n",
        "cnn_model = CNN_TUMOR(params_model)\n",
        "\n",
        "# define computation hardware approach (GPU/CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = cnn_model.to(device)"
      ],
      "metadata": {
        "id": "vpXL9VArnqr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Summary for CNN Model\n",
        "summary(cnn_model, input_size=(3, 256, 256),device=device.type)"
      ],
      "metadata": {
        "id": "e38cOZ7Pnu_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optim.Adam(cnn_model.parameters(), lr=3e-4)\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20,verbose=1)"
      ],
      "metadata": {
        "id": "MbAuMCABnwJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_Val(model, params,verbose=False):\n",
        "\n",
        "    # Get the parameters\n",
        "    epochs=params[\"epochs\"]\n",
        "    loss_func=params[\"f_loss\"]\n",
        "    opt=params[\"optimiser\"]\n",
        "    train_dl=params[\"train\"]\n",
        "    val_dl=params[\"val\"]\n",
        "    lr_scheduler=params[\"lr_change\"]\n",
        "    weight_path=params[\"weight_path\"]\n",
        "\n",
        "    # history of loss values in each epoch\n",
        "    loss_history={\"train\": [],\"val\": []}\n",
        "    # histroy of metric values in each epoch\n",
        "    metric_history={\"train\": [],\"val\": []}\n",
        "    # a deep copy of weights for the best performing model\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    # initialize best loss to a large value\n",
        "    best_loss=float('inf')\n",
        "\n",
        "# Train Model n_epochs (the progress of training by printing the epoch number and the associated learning rate. It can be helpful for debugging, monitoring the learning rate schedule, or gaining insights into the training process.)\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        # Get the Learning Rate\n",
        "        current_lr=get_lr(opt)\n",
        "        if(verbose):\n",
        "            print('Epoch {}/{}, current lr={}'.format(epoch, epochs - 1, current_lr))\n",
        "\n",
        "\n",
        "# Train Model Process\n",
        "\n",
        "\n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(model,loss_func,train_dl,opt)\n",
        "\n",
        "        # collect losses\n",
        "        loss_history[\"train\"].append(train_loss)\n",
        "        metric_history[\"train\"].append(train_metric)\n",
        "\n",
        "\n",
        "# Evaluate Model Process\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(model,loss_func,val_dl)\n",
        "\n",
        "        # store best model\n",
        "        if(val_loss < best_loss):\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            # store weights into a local file\n",
        "            torch.save(model.state_dict(), weight_path)\n",
        "            if(verbose):\n",
        "                print(\"Copied best model weights!\")\n",
        "\n",
        "        # collect loss and metric for validation dataset\n",
        "        loss_history[\"val\"].append(val_loss)\n",
        "        metric_history[\"val\"].append(val_metric)\n",
        "\n",
        "        # learning rate schedule\n",
        "        lr_scheduler.step(val_loss)\n",
        "        if current_lr != get_lr(opt):\n",
        "            if(verbose):\n",
        "                print(\"Loading best model weights!\")\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "        if(verbose):\n",
        "            print(f\"train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}\")\n",
        "            print(\"-\"*10)\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, loss_history, metric_history"
      ],
      "metadata": {
        "id": "PRrsfhLonziE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define various parameters used for training and evaluation of a cnn_model\n",
        "\n",
        "params_train={\n",
        " \"train\": train_loader,\"val\": val_loader,\n",
        " \"epochs\": 60,\n",
        " \"optimiser\": optim.Adam(cnn_model.parameters(),lr=3e-4),\n",
        " \"lr_change\": ReduceLROnPlateau(opt,\n",
        "                                mode='min',\n",
        "                                factor=0.5,\n",
        "                                patience=20,\n",
        "                                verbose=0),\n",
        " \"f_loss\": nn.NLLLoss(reduction=\"sum\"),\n",
        " \"weight_path\": \"weights.pt\",\n",
        "}\n",
        "\n",
        "# train and validate the model\n",
        "cnn_model,loss_hist,metric_hist = Train_Val(cnn_model,params_train)"
      ],
      "metadata": {
        "id": "CRPicSR_n4DX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convergence History Plot\n",
        "epochs=params_train[\"epochs\"]\n",
        "fig,ax = plt.subplots(1,2,figsize=(12,5))\n",
        "\n",
        "sns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"train\"],ax=ax[0],label='loss_hist[\"train\"]')\n",
        "sns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"val\"],ax=ax[0],label='loss_hist[\"val\"]')\n",
        "sns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"train\"],ax=ax[1],label='Acc_hist[\"train\"]')\n",
        "sns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"val\"],ax=ax[1],label='Acc_hist[\"val\"]')\n",
        "\n",
        "# define function For Classification Report\n",
        "def Ture_and_Pred(val_loader, model):\n",
        "    i = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.numpy()\n",
        "        outputs = model(images)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "\n",
        "        y_true = np.append(y_true, labels)\n",
        "        y_pred = np.append(y_pred, pred)\n",
        "\n",
        "    return y_true, y_pred\n",
        "\n",
        "\n",
        "# check confusion matrix for error analysis\n",
        "y_true, y_pred = Ture_and_Pred(val_loader, cnn_model)\n",
        "\n",
        "print(classification_report(y_true, y_pred), '\\n\\n')\n",
        "cm = confusion_matrix(y_true, y_pred)"
      ],
      "metadata": {
        "id": "FC4sqpyJn7K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix Plotting Function\n",
        "def show_confusion_matrix(cm, CLA_label, title='Confusion matrix', cmap=plt.cm.YlGnBu):\n",
        "\n",
        "    plt.figure(figsize=(10,7))\n",
        "    plt.grid(False)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(CLA_label))\n",
        "\n",
        "    plt.xticks(tick_marks, [f\"{value}={key}\" for key , value in CLA_label.items()], rotation=45)\n",
        "    plt.yticks(tick_marks, [f\"{value}={key}\" for key , value in CLA_label.items()])\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, f\"{cm[i,j]}\\n{cm[i,j]/np.sum(cm)*100:.2f}%\", horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_confusion_matrix(cm, CLA_label)"
      ],
      "metadata": {
        "id": "0Smc9npNoHdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cnn_model, \"Brain_Tumor_model.pt\")"
      ],
      "metadata": {
        "id": "RTh7TrVjoJAI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}